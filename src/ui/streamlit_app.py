"""Streamlit å‰ç«¯ï¼ˆæ–°ç‰ˆæ˜ å°„ä¸åˆ†ç»„æ–‡æ¡ˆï¼‰

- ä½¿ç”¨ç¯å¢ƒå˜é‡ API_URL è®¿é—®åç«¯ï¼ˆé»˜è®¤ http://localhost:8000ï¼‰
"""

import os
from typing import Dict, Optional
import requests
import streamlit as st
import pandas as pd


API_BASE_URL = os.environ.get("API_URL", "http://127.0.0.1:8000")
os.environ.setdefault("NO_PROXY", "localhost,127.0.0.1,::1")
SESSION = requests.Session()
try:
    SESSION.trust_env = False
except Exception:
    pass


def call_api(endpoint: str, method: str = "GET", data: Optional[Dict] = None, files: Optional[Dict] = None):
    url = f"{API_BASE_URL}{endpoint}"
    try:
        if method == "GET":
            resp = SESSION.get(url, params=data, timeout=20)
        else:
            if files:
                resp = SESSION.post(url, data=data, files=files, timeout=120)
            else:
                resp = SESSION.post(url, json=data, timeout=60)
        resp.raise_for_status()
        return resp.json()
    except Exception as e:
        st.error(f"API è¯·æ±‚å¤±è´¥: {e}  (API: {API_BASE_URL})")
        return None


st.set_page_config(page_title="æ¡ˆä¾‹çŸ¥è¯†ç‚¹åŒ¹é…ç³»ç»Ÿ", layout="wide")

st.title("ğŸ“š æ¡ˆä¾‹çŸ¥è¯†ç‚¹åŒ¹é…ç³»ç»Ÿ")

with st.sidebar:
    st.markdown("### åŠŸèƒ½é€‰æ‹©")
    page = st.radio("è¯·é€‰æ‹©åŠŸèƒ½", ["æ¡ˆä¾‹åˆ†æ", "ç†è®ºæŸ¥è¯¢", "æ¡ˆä¾‹æ£€ç´¢"], label_visibility="collapsed")
    st.markdown("---")
    health = call_api("/health")
    if health:
        st.success("åç«¯æœåŠ¡åœ¨çº¿")
        stats = call_api("/stats")
        if stats:
            st.metric("æ•°æ®åº“æ¡ˆä¾‹æ•°", stats.get("total_cases", 0))
            st.metric("ç†è®ºçŸ¥è¯†ç‚¹æ•°", stats.get("total_theories", 0))
    else:
        st.error("åç«¯æœåŠ¡ç¦»çº¿")


if page == "æ¡ˆä¾‹åˆ†æ":
    st.subheader("æ¡ˆä¾‹è¾“å…¥")
    input_method = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼", ["PDFæ–‡ä»¶ä¸Šä¼ ", "æ–‡æœ¬è¾“å…¥"], horizontal=True)

    col1, col2 = st.columns(2)
    with col1:
        case_name = st.text_input("æ¡ˆä¾‹åç§° *")
        author = st.text_input("ä½œè€…", placeholder="å¯é€‰")
        subject = st.text_input("å­¦ç§‘é¢†åŸŸ", placeholder="å¦‚ï¼šå¸‚åœºè¥é”€ã€æˆ˜ç•¥ç®¡ç†ç­‰")
    with col2:
        industry = st.text_input("è¡Œä¸š", placeholder="å¦‚ï¼šåˆ¶é€ ä¸šã€é‡‘èç­‰")
        keywords = st.text_input("å…³é”®è¯", placeholder="å¤šä¸ªç”¨é€—å·åˆ†éš”")
        theories_input = st.text_input("ä¸»è¦ç†è®º (å¯é€‰)", placeholder="ç•™ç©ºåˆ™è‡ªåŠ¨è¯†åˆ«ï¼›å¤šä¸ªç”¨é€—å·åˆ†éš”")

    if input_method == "PDFæ–‡ä»¶ä¸Šä¼ ":
        uploaded_file = st.file_uploader("ä¸Šä¼  PDF æ–‡ä»¶", type=["pdf"])
        if st.button("å¼€å§‹åˆ†æ", type="primary", disabled=not (case_name and uploaded_file)):
            with st.spinner("æ­£åœ¨åˆ†æ..."):
                data = {"name": case_name}
                if author: data["author"] = author
                if subject: data["subject"] = subject
                if industry: data["industry"] = industry
                if keywords: data["keywords"] = keywords
                if theories_input:
                    data["theories"] = theories_input
                    data["primary_theories"] = theories_input  # ä¸»è¦ç†è®º
                files = {"file": (uploaded_file.name, uploaded_file.getvalue(), "application/pdf")}
                result = call_api("/analyze/upload", method="POST", data=data, files=files)
                if result:
                    st.session_state.analysis_result = result
    else:
        case_text = st.text_area("æ¡ˆä¾‹æ–‡æœ¬ *", height=300)
        if st.button("å¼€å§‹åˆ†æ", type="primary", disabled=not (case_name and case_text)):
            with st.spinner("æ­£åœ¨åˆ†æ..."):
                data = {"name": case_name, "text": case_text}
                if author: data["author"] = author
                if subject: data["subject"] = subject
                if industry: data["industry"] = industry
                if keywords: data["keywords"] = keywords
                if theories_input:
                    theory_list = [t.strip() for t in theories_input.split(',') if t.strip()]
                    data["theories"] = theory_list
                    data["primary_theories"] = theory_list  # ä¸»è¦ç†è®º
                result = call_api("/analyze/text", method="POST", data=data)
                if result:
                    st.session_state.analysis_result = result

    if hasattr(st.session_state, 'analysis_result'):
        st.markdown("---")
        st.subheader("åˆ†æç»“æœ")
        result = st.session_state.analysis_result

        # åˆ›æ–°åº¦æŒ‡æ ‡ï¼ˆæ–°åˆ†ç»„æ–‡æ¡ˆï¼‰
        st.markdown("### åˆ›æ–°åº¦è¯„ä¼°")
        innovation = result.get("innovation_score", {})
        score = innovation.get("innovation_score", 0)
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            st.metric("åˆ›æ–°åº¦æ€»åˆ†", f"{score:.1f}", help="åŸºäºç†è®ºé¢‘æ¬¡åˆæˆ (0-100)")
        with c2:
            st.metric("æ–°é¢–ç†è®º(â‰¤2)", f"{len(innovation.get('novel_theories', []))} é¡¹")
        with c3:
            st.metric("å¸¸è§ç†è®º(3-4)", f"{len(innovation.get('common_theories', []))} é¡¹")
        with c4:
            st.metric("ç»å…¸ç†è®º(â‰¥5)", f"{len(innovation.get('high_frequency_theories', []))} é¡¹")

        # ç†è®ºåŒ¹é…
        st.markdown("### ç†è®ºåŒ¹é…ç»“æœ")
        theories = result.get("identified_theories", [])
        primary_theories = result.get("primary_theories", []) or []
        exact_matches = result.get("exact_matches", {})

        # åˆ†ç¦»ä¸»è¦ç†è®ºå’Œå…¶ä»–ç†è®º
        if primary_theories:
            # æœ‰ä¸»è¦ç†è®ºæ—¶ï¼Œåˆ†ä¸¤éƒ¨åˆ†æ˜¾ç¤º
            st.markdown("#### ğŸ“Œ ä¸»è¦ç†è®ºæŸ¥é‡")
            primary_found = False
            for t in [t for t in theories if t in primary_theories and t in exact_matches]:
                primary_found = True
                info = exact_matches[t]
                cases = info.get('cases', [])
                with st.expander(f"â­ {t} - ä½¿ç”¨ {info.get('match_count', 0)} æ¬¡ï¼ˆ{info.get('frequency_rank','æœªçŸ¥')}ï¼‰", expanded=True):
                    if cases:
                        df = pd.DataFrame([
                            {
                                "æ¡ˆä¾‹åç§°": c.get('name', 'N/A'),
                                "æ¡ˆä¾‹ç¼–å·": c.get('code', 'N/A'),
                                "å¹´ä»½": c.get('year', 'N/A'),
                                "å­¦ç§‘": c.get('subject', 'N/A'),
                                "è¡Œä¸š": c.get('industry', 'N/A'),
                            } for c in cases
                        ])
                        st.dataframe(df, use_container_width=True, hide_index=True)
            if not primary_found:
                st.info("æœªæ‰¾åˆ°ä¸»è¦ç†è®ºçš„åŒ¹é…ç»“æœ")

            st.markdown("#### ğŸ“š å…¶ä»–ç†è®ºæŸ¥é‡")
            other_theories = [t for t in theories if t not in primary_theories and t in exact_matches]
            if other_theories:
                for t in other_theories:
                    info = exact_matches[t]
                    cases = info.get('cases', [])
                    with st.expander(f"{t} - ä½¿ç”¨ {info.get('match_count', 0)} æ¬¡ï¼ˆ{info.get('frequency_rank','æœªçŸ¥')}ï¼‰"):
                        if cases:
                            df = pd.DataFrame([
                                {
                                    "æ¡ˆä¾‹åç§°": c.get('name', 'N/A'),
                                    "æ¡ˆä¾‹ç¼–å·": c.get('code', 'N/A'),
                                    "å¹´ä»½": c.get('year', 'N/A'),
                                    "å­¦ç§‘": c.get('subject', 'N/A'),
                                    "è¡Œä¸š": c.get('industry', 'N/A'),
                                } for c in cases
                            ])
                            st.dataframe(df, use_container_width=True, hide_index=True)
            else:
                st.info("æœªæ‰¾åˆ°å…¶ä»–ç†è®ºçš„åŒ¹é…ç»“æœ")
        else:
            # æ²¡æœ‰ä¸»è¦ç†è®ºæ—¶ï¼ŒæŒ‰åŸæ ·æ˜¾ç¤º
            if exact_matches:
                for t in [t for t in theories if t in exact_matches]:
                    info = exact_matches[t]
                    cases = info.get('cases', [])
                    with st.expander(f"{t} - ä½¿ç”¨ {info.get('match_count', 0)} æ¬¡ï¼ˆ{info.get('frequency_rank','æœªçŸ¥')}ï¼‰"):
                        if cases:
                            df = pd.DataFrame([
                                {
                                    "æ¡ˆä¾‹åç§°": c.get('name', 'N/A'),
                                    "æ¡ˆä¾‹ç¼–å·": c.get('code', 'N/A'),
                                    "å¹´ä»½": c.get('year', 'N/A'),
                                    "å­¦ç§‘": c.get('subject', 'N/A'),
                                    "è¡Œä¸š": c.get('industry', 'N/A'),
                                } for c in cases
                            ])
                            st.dataframe(df, use_container_width=True, hide_index=True)
            else:
                st.info("æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")

        # ç›¸ä¼¼æ¡ˆä¾‹æ’å
        st.markdown("### ç›¸ä¼¼æ¡ˆä¾‹æ’å")
        similar_cases = result.get("similar_cases", [])
        if similar_cases:
            rows = []
            for i, c in enumerate(similar_cases, 1):
                meta = c.get('metadata', {})
                scs = c.get('scores', {})
                rows.append({
                    "æ’å": i,
                    "æ¡ˆä¾‹åç§°": meta.get('name', 'N/A'),
                    "å¹´ä»½": meta.get('year', 'N/A'),
                    "ç»¼åˆç›¸ä¼¼åº¦": f"{scs.get('final_score', 0):.3f}",
                    "è¯­ä¹‰ç›¸ä¼¼åº¦": f"{scs.get('semantic_similarity', 0):.3f}",
                    "å­¦ç§‘": meta.get('subject', 'N/A'),
                })
            st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
        else:
            st.info("æœªæ‰¾åˆ°ç›¸ä¼¼æ¡ˆä¾‹")


elif page == "ç†è®ºæŸ¥è¯¢":
    st.subheader("ç†è®ºçŸ¥è¯†ç‚¹æŸ¥è¯¢ï¼ˆæ”¯æŒåŒä¹‰åˆå¹¶ï¼‰")
    theories = call_api("/theories/") or []
    q = st.text_input("è¾“å…¥ç†è®ºå…³é”®è¯è¿›è¡Œæœç´¢", placeholder="å¦‚ SWOT / è“æµ· / æ³¢ç‰¹äº”åŠ› ...")
    if q:
        # ç›´æ¥è°ƒç”¨å¯¹åº” APIï¼Œè¿”å›å³ä¸ºæ ‡å‡†åŒ–åçš„åˆå¹¶ç»“æœ
        res = call_api(f"/theories/{q}/cases")
        if res:
            st.write(f"æ ‡å‡†åŒ–åç§°ï¼š{res.get('theory_name')}")
            st.write(f"ä½¿ç”¨æ¬¡æ•°ï¼š{res.get('usage_count')}  Â·  é¢‘æ¬¡ç­‰çº§ï¼š{res.get('frequency_rank')}")
            cases = res.get('cases', [])
            if cases:
                st.dataframe(pd.DataFrame(cases), use_container_width=True)
    else:
        st.info("è¾“å…¥å…³é”®è¯åå›è½¦æŸ¥è¯¢")


elif page == "æ¡ˆä¾‹æ£€ç´¢":
    st.subheader("æ¡ˆä¾‹æ£€ç´¢")
    col1, col2 = st.columns(2)
    with col1:
        kw = st.text_input("å…³é”®è¯")
        subj = st.text_input("å­¦ç§‘")
    with col2:
        ind = st.text_input("è¡Œä¸š")
        year = st.text_input("å¹´ä»½")
    limit = st.slider("è¿”å›æ•°é‡", 10, 100, 50, 10)
    if st.button("å¼€å§‹æ£€ç´¢", type="primary"):
        params = {"limit": limit}
        if kw: params['keyword'] = kw
        if subj: params['subject'] = subj
        if ind: params['industry'] = ind
        if year: params['year'] = year
        res = call_api("/cases/search", method="GET", data=params)
        if res:
            st.dataframe(pd.DataFrame(res.get('cases', [])), use_container_width=True, hide_index=True)
